{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub as kh\n",
    "\n",
    "mohamedbakhet_amazon_books_reviews_path = kh.dataset_download('mohamedbakhet/amazon-books-reviews')\n",
    "print(mohamedbakhet_amazon_books_reviews_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(mohamedbakhet_amazon_books_reviews_path):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "books_rating_path = os.path.join(mohamedbakhet_amazon_books_reviews_path, \"books_rating.csv\")\n",
    "books_data_path = os.path.join(mohamedbakhet_amazon_books_reviews_path, \"books_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Id in the book_rating dataset is different from the Id used in the book data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "books_rating_raw = pd.read_csv(books_rating_path, header=0)\n",
    "books_rating_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The title is unique and can be used as item ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "books_data_raw = pd.read_csv(books_data_path, header=0)\n",
    "books_data_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Convert original dataset to a clean dataset, such as missing value, get global lookup table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Rename columns to remove special characters\n",
    "books_rating = books_rating_raw.rename(columns={\n",
    "    \"review/helpfulness\": \"reviewHelpfulness\", \n",
    "    \"review/score\": \"reviewScore\", \n",
    "    \"review/time\": \"reviewTime\", \n",
    "    \"review/summary\": \"reviewSummary\", \n",
    "    \"review/text\": \"reviewText\",\n",
    "    \"User_id\": \"userId\",\n",
    "    \"Id\": \"id\",\n",
    "    \"Title\": \"title\",\n",
    "    \"Price\": \"price\",\n",
    "})\n",
    "\n",
    "# Rename columns of books_data to use camel case\n",
    "books_data = books_data_raw.rename(columns={\n",
    "    \"Title\": \"title\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "books_data[\"bookId\"] = books_data.infoLink.str.extract(r\"id=([^&]+)\")\n",
    "books_data[\"title\"] = books_data.title.fillna(\"\")\n",
    "\n",
    "# Fillna\n",
    "books_rating.fillna({\"userId\": \"00000000000000\"}, inplace=True) # Use '00000000000000' for unknown User_id\n",
    "books_rating.fillna({\"id\": \"0000000000\"}, inplace=True) # Use '0000000000' for unknown book ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Test Split\n",
    "\n",
    "The train / test split needs to happen before negative sampling. Use leave-last-out for test set.\n",
    "* For users with 1 review, the only review is used as training data.\n",
    "* For users with 2 review, the 2nd review is used as validation, and no testing data is used from this user.\n",
    "* for users with 3 review and more, the last two reviews are used for validation and testing respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by userId and add rownumber per row based on reviewTime on ascending order\n",
    "books_rating['userRatingSeqNum'] = books_rating.sort_values(['userId', 'reviewTime']).groupby('userId').cumcount() + 1\n",
    "books_rating['userTotalRatings'] = books_rating.groupby('userId')['reviewTime'].transform('count')\n",
    "\n",
    "books_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the train/validation/test split strategy decided, create a new column 'dataSplit' to indicate which split the row belongs to\n",
    "def assign_data_split(row):\n",
    "    if row['userTotalRatings'] == 1:\n",
    "        return 'train'\n",
    "    elif row['userTotalRatings'] == 2:\n",
    "        if row['userRatingSeqNum'] == 1:\n",
    "            return 'train'\n",
    "        else:\n",
    "            return 'validation'\n",
    "    else:\n",
    "        if row['userRatingSeqNum'] == row['userTotalRatings']:\n",
    "            return 'test'\n",
    "        elif row['userRatingSeqNum'] == row['userTotalRatings'] - 1:\n",
    "            return 'validation'\n",
    "        else:\n",
    "            return 'train'\n",
    "\n",
    "# Split the book_rating dataframe into train, validation, and test sets\n",
    "books_rating['dataSplit'] = books_rating.apply(assign_data_split, axis=1)\n",
    "\n",
    "books_rating_train = books_rating[books_rating['dataSplit'] == 'train']\n",
    "books_rating_validation = books_rating[books_rating['dataSplit'] == 'validation']\n",
    "books_rating_test = books_rating[books_rating['dataSplit'] == 'test']\n",
    "\n",
    "# Print the sizes of each split\n",
    "print(f\"Training set size: {len(books_rating_train)}\")\n",
    "print(f\"Validation set size: {len(books_rating_validation)}\")\n",
    "print(f\"Test set size: {len(books_rating_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate user2idx and item2idx mappings using the books_rating dataset\n",
    "raw_user_ids = sorted(list(set(books_rating.userId))) # sort raw ID for reproduceability\n",
    "user2idx = {raw_user_id:idx for idx, raw_user_id in enumerate(raw_user_ids)}\n",
    "\n",
    "raw_book_ids = sorted(list(set(books_data.title))) # sort raw ID for reproduceability\n",
    "item2idx = {raw_book_id:idx for idx, raw_book_id in enumerate(raw_book_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a dataset, a dataloader\n",
    "class TwoTowersDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 df_interaction=None, df_catalog=None,\n",
    "                 user2idx=None, item2idx=None,\n",
    "                 interaction_csv_path=None, interaction_header=0,\n",
    "                 catalog_csv_path=None, catalog_header=0, \n",
    "                 random_negative_samples=0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.random_negative_samples = random_negative_samples\n",
    "        \n",
    "        # Load interaction\n",
    "        if df_interaction is not None:\n",
    "            self.df_interaction = df_interaction.reset_index(drop=True)\n",
    "        elif interaction_csv_path is not None:\n",
    "            self.df_interaction = pd.read_csv(interaction_csv_path, header=interaction_header)\n",
    "        \n",
    "        # Load catalog\n",
    "        if df_catalog is not None:\n",
    "            self.df_catalog = df_catalog.reset_index(drop=True)\n",
    "        elif catalog_csv_path is not None:\n",
    "            self.df_catalog = pd.read_csv(catalog_csv_path, header=catalog_header)\n",
    "        \n",
    "        # Item ID lookup\n",
    "        if item2idx is not None:\n",
    "            self.book2idx = item2idx\n",
    "            self.idx2book = {idx:raw_book_id for raw_book_id, idx in item2idx.items()}\n",
    "            self.books = [raw_book_id for raw_book_id, idx in item2idx.items()]\n",
    "        else:\n",
    "            raw_book_ids = sorted(list(set(self.df_catalog[\"title\"]))) # sort raw ID for reproduceability\n",
    "            self.books = [raw_book_id for idx, raw_book_id in enumerate(raw_book_ids)]\n",
    "            self.book2idx = {raw_book_id:idx for idx, raw_book_id in enumerate(raw_book_ids)}\n",
    "            self.idx2book = {idx:raw_book_id for idx, raw_book_id in enumerate(raw_book_ids)}\n",
    "        \n",
    "        # User ID lookup\n",
    "        if user2idx is not None:\n",
    "            self.user2idx = user2idx\n",
    "            self.idx2user = {idx:raw_user_id for raw_user_id, idx in user2idx.items()}\n",
    "            self.users = [raw_user_id for raw_user_id, idx in user2idx.items()]\n",
    "        else:\n",
    "            raw_user_ids = sorted(list(set(self.df_interaction.userId))) # sort raw ID for reproduceability\n",
    "            self.users = [raw_user_id for raw_user_id in enumerate(raw_user_ids)]\n",
    "            self.user2idx = {raw_user_id:idx for idx, raw_user_id in enumerate(raw_user_ids)}\n",
    "            self.idx2user = {idx:raw_user_id for idx, raw_user_id in enumerate(raw_user_ids)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df_interaction)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get all interactions from a user.\n",
    "\n",
    "        Args\n",
    "        idx: interaction\n",
    "        \"\"\"\n",
    "        # Get positive interaction\n",
    "        pos_interaction = self.df_interaction.iloc[idx, :]\n",
    "        user_id = pos_interaction.userId\n",
    "        pos_item_id = pos_interaction.title\n",
    "        all_pos_items = set(self.df_interaction[self.df_interaction.userId == user_id].title)\n",
    "        # Random sample for negatives\n",
    "        max_attempt = 1e3 # maximum attempt 1000 times\n",
    "        all_neg_items = np.array(list(set(self.books) - all_pos_items))\n",
    "        neg_sample_items = all_neg_items[np.random.randint(0, len(all_neg_items), self.random_negative_samples)]\n",
    "        # Return data item\n",
    "        return {\n",
    "            \"user_ids\": torch.tensor(self.user2idx.get(user_id, 0), dtype=torch.long), # 0 is unknown user ID\n",
    "            \"item_ids\": torch.tensor([self.book2idx.get(pos_item_id, 0)] + [self.book2idx.get(neg_item_id, 0) for neg_item_id in neg_sample_items], dtype=torch.long),\n",
    "            \"binary_scores\": torch.tensor([1] + [0 for neg_item_id in neg_sample_items], dtype=torch.float) \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_ds = TwoTowersDataset(\n",
    "    df_interaction=books_rating_train, \n",
    "    user2idx=user2idx,\n",
    "    item2idx=item2idx,\n",
    "    random_negative_samples = 10\n",
    ")\n",
    "\n",
    "validation_ds = TwoTowersDataset(\n",
    "    df_interaction=books_rating_validation, \n",
    "    user2idx=user2idx,\n",
    "    item2idx=item2idx,\n",
    "    random_negative_samples = 10\n",
    ")\n",
    "\n",
    "test_ds = TwoTowersDataset(\n",
    "    df_interaction=books_rating_test,\n",
    "    user2idx=user2idx,\n",
    "    item2idx=item2idx,\n",
    "    random_negative_samples = 100\n",
    ")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_ds)}\")\n",
    "print(\"Train dataset sample:\")\n",
    "print(train_ds[0])\n",
    "\n",
    "print(f\"Validation dataset size: {len(validation_ds)}\")\n",
    "print(\"Validation dataset sample:\")\n",
    "print(validation_ds[0])\n",
    "\n",
    "print(f\"Test dataset size: {len(test_ds)}\")\n",
    "print(\"Test dataset sample:\")\n",
    "print(test_ds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Towers Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create user tower\n",
    "class UserTower(nn.Module):\n",
    "    def __init__(self, num_users, id_emb_dim, tower_emb_dim):\n",
    "        \"\"\"\n",
    "        User tower that converts user features into a user embedding for dot product.\n",
    "\n",
    "        Args:\n",
    "        num_users - total users\n",
    "        id_emb_dim - Dimension of user ID embedding\n",
    "        tower_emb_dim - Dimension of user tower embedding\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.id_emb = nn.Embedding(num_users, id_emb_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(id_emb_dim, tower_emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(tower_emb_dim, tower_emb_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, user_id):\n",
    "        x = self.id_emb(user_id) # [B, id_emb_dim]\n",
    "        x = self.mlp(x)\n",
    "        # Apply L2 normalization so to enable cosine similarity using x instead of unbounded dot product\n",
    "        x = x / x.norm(dim=-1, keepdim=True)\n",
    "        return x\n",
    "\n",
    "\n",
    "user_id_emb_dim = 32\n",
    "user_tower_emb_dim = 32\n",
    "num_users = len(user2idx)\n",
    "\n",
    "user_tower = UserTower(num_users, user_id_emb_dim, user_tower_emb_dim)\n",
    "user_tower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create item tower\n",
    "class ItemTower(nn.Module):\n",
    "    def __init__(self, num_items, id_emb_dim, tower_emb_dim):\n",
    "        super().__init__()\n",
    "        self.id_emb = nn.Embedding(num_items, id_emb_dim) # [num_items, id_emb_dim]\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(id_emb_dim, tower_emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(tower_emb_dim, tower_emb_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, item_id):\n",
    "        \"\"\"Calculate item tower embedding.\n",
    "\n",
    "        Args:\n",
    "        item_id - Item ID\n",
    "        \n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        x = self.id_emb(item_id)  # [B, id_emb_dim]\n",
    "        x = self.mlp(x) # [B, tower_emb_dim]\n",
    "        x = x / x.norm(dim = -1, keepdim=True) # [B, tower_emb_dim]\n",
    "        return x\n",
    "\n",
    "num_items = len(item2idx)\n",
    "id_emb_dim = 32\n",
    "tower_emb_dim = 32\n",
    "\n",
    "item_tower = ItemTower(num_items, id_emb_dim, tower_emb_dim)\n",
    "item_tower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-towers model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create two-towers model\n",
    "\n",
    "class TwoTowersModel(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        # Item tower dimension [item_id_emb_dim, item_tower_emb_dim]\n",
    "        self.item_tower = ItemTower(\n",
    "            num_items = kwargs.get(\"num_items\", 0),\n",
    "            id_emb_dim = kwargs.get(\"item_id_emb_dim\", 32),\n",
    "            tower_emb_dim = kwargs.get(\"item_tower_emb_dim\", 32),\n",
    "        )\n",
    "        # User tower dimension [user_id_emb_dim, user_tower_emb_dim]\n",
    "        self.user_tower = UserTower(\n",
    "            num_users = kwargs.get(\"num_users\", 0),\n",
    "            id_emb_dim = kwargs.get(\"user_id_emb_dim\", 32),\n",
    "            tower_emb_dim = kwargs.get(\"user_tower_emb_dim\", 32),\n",
    "        )\n",
    "\n",
    "    def forward(self, user_id, item_id):\n",
    "        \"\"\"Because item_emb and user_emb are normalised in the tower. The dot product here\n",
    "        is then the cosine similarity, and its value is between [-1, 1].\n",
    "\n",
    "        Args\n",
    "        user_id - User IDs, [B,]\n",
    "        item_id - Item IDs, [B,]\n",
    "        \"\"\"\n",
    "        item_emb = self.item_tower(item_id) # [B, item_tower_dim]. Normalised into Cosine similarity \n",
    "        user_emb = self.user_tower(user_id) # [B, user_tower_dim]. Normalised into Cosine similarity\n",
    "        x = (item_emb * user_emb).sum(axis=-1, keepdim=True).squeeze() # [B]. x elements are between -1 and 1.\n",
    "        x = nn.Sigmoid()(x) # Output in [0, 1] for BCE\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_item_ids = torch.tensor([0], dtype=torch.long)\n",
    "test_user_ids = torch.tensor([0], dtype=torch.long)\n",
    "\n",
    "num_items = len(item2idx)\n",
    "num_users = len(user2idx)\n",
    "\n",
    "test_model = TwoTowersModel(\n",
    "    num_items=num_items, \n",
    "    num_users=num_users\n",
    ")\n",
    "test_model(user_id=test_user_ids, item_id=test_item_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train\n",
    "\n",
    "Train the two-towers model and monitor the loss and training epoch\n",
    "* Start with Binary Cross Entropy loss\n",
    "* Switch to Negative Contrastive Ex loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EPOCH = 1\n",
    "BATCH_SIZE = 256\n",
    "MAX_BATCHES = None\n",
    "LOG_INTERVAL = 1\n",
    "\n",
    "# Create dataloader\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dl = DataLoader(validation_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Build model\n",
    "num_items = len(item2idx)\n",
    "num_users = len(user2idx)\n",
    "model = TwoTowersModel(    \n",
    "    num_items=num_items,\n",
    "    num_users=num_users\n",
    ")\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a in-batch negative dataset that generates negative training samples from other user's positive items\n",
    "# The negative sampling dataset needs to be created for training and test individually\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Train\n",
    "    # -------------------------------------------------------\n",
    "    train_loss = 0.0\n",
    "    for i, batch in enumerate(train_dl):\n",
    "        print(\"Starting batch\", i)\n",
    "        batch_start_time = time()\n",
    "        if MAX_BATCHES is not None and i >= MAX_BATCHES:\n",
    "            break\n",
    "        model.train()\n",
    "        # Prepare Two-towers input\n",
    "        item_ids = batch[\"item_ids\"] # [B, K+1], K is number of negative samples, 1 is positive interaction\n",
    "        labels = batch[\"binary_scores\"] # [B, K+1]\n",
    "        user_ids = batch[\"user_ids\"] # [B, ]\n",
    "        user_ids_exp = user_ids.unsqueeze(1).expand(-1, item_ids.shape[1]) # [B, K+1]\n",
    "        # Flatten \n",
    "        user_ids_flat = user_ids_exp.reshape(-1) # [B*(K+1),]\n",
    "        item_ids_flat = item_ids.reshape(-1) # [B*(K+1),]\n",
    "        labels_flat = labels.reshape(-1) # [B*(K+1),]\n",
    "        # Forward Pass\n",
    "        logit = model(user_ids_flat, item_ids_flat) # forward pass\n",
    "        batch_loss = loss_fn(logit, labels_flat)\n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"Finished backprop of training batch\", i)\n",
    "        train_loss += batch_loss.item()    \n",
    "        batch_finish_time = time()\n",
    "        elapsed_time = batch_finish_time - batch_start_time\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # Monitoring\n",
    "        # -------------------------------------------------------\n",
    "        if (i+1) % LOG_INTERVAL == 0:\n",
    "            print(f\"epoch {epoch+1}, batch {i+1}, \"\n",
    "                  f\"train loss: {batch_loss.item():.4f}, \"\n",
    "                  f\"user_ids: {user_ids.shape}, \"\n",
    "                  f\"item_ids: {item_ids.shape}, \"\n",
    "                  f\"labels: {labels.shape}, \"\n",
    "                  f\"elapsed time: {elapsed_time:.1f}s\"\n",
    "            )\n",
    "        print(\"Finished batch\", i)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Validation\n",
    "    # -------------------------------------------------------\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for j, val_batch in enumerate(validation_dl):\n",
    "            val_item_ids = val_batch[\"item_ids\"] # [B, K+1], K is number of negative samples, 1 is positive interaction\n",
    "            val_labels = val_batch[\"binary_scores\"] # [B, K+1]\n",
    "            val_user_ids = val_batch[\"user_ids\"] # [B, ]\n",
    "            val_user_ids_exp = val_user_ids.unsqueeze(1).expand(-1, val_item_ids.shape[1]) # [B, K+1]\n",
    "            # Flatten \n",
    "            val_user_ids_flat = val_user_ids_exp.reshape(-1) # [B*(K+1),]\n",
    "            val_item_ids_flat = val_item_ids.reshape(-1) # [B*(K+1),]\n",
    "            val_labels_flat = val_labels.reshape(-1) # [B*(K+1),]\n",
    "            # Forward Pass\n",
    "            val_logit = model(val_user_ids_flat, val_item_ids_flat) # forward pass\n",
    "            val_batch_loss = loss_fn(val_logit, val_labels_flat)\n",
    "            val_loss += val_batch_loss.item()\n",
    "    \n",
    "    print(f\"epoch {epoch+1} completed. \"\n",
    "          f\"Average train loss: {train_loss / len(train_dl):.4f}, \"\n",
    "          f\"Average validation loss: {val_loss / len(validation_dl):.4f}\"\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Calculate offline performance metrics on the train, validation and test set\n",
    "* Hit@K\n",
    "* Recall@K\n",
    "* Normalised Weighted Cumulative Gain@K\n",
    "* Mean Reciprocal Rank@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2476732,
     "sourceId": 4200454,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "two_tower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
