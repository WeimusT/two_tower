{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a73f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Dict, List, Sequence, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b913bd32",
   "metadata": {},
   "source": [
    "# Two-Towers Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc2ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 10000\n",
    "n_items = 50000\n",
    "n_countries = 50\n",
    "n_categories = 200\n",
    "emb_dim = 32 # embedding dimension per feature\n",
    "tower_dim = 64 # output dimension of each tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215e1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 2. Define the two towers\n",
    "# ---------------------------\n",
    "class UserTower(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, emb_dim)\n",
    "        self.country_emb = nn.Embedding(n_countries, emb_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 2, tower_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(tower_dim, tower_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, user_id, country_id):\n",
    "        \"\"\"\n",
    "        Perform forward pass of user tower.\n",
    "\n",
    "        Args:\n",
    "            user_id: Tensor of shape (batch_size,)\n",
    "            country_id: Tensor of shape (batch_size,)\n",
    "        \"\"\"\n",
    "        u_id = self.user_emb(user_id) # (batch_size, emb_dim)\n",
    "        u_country = self.country_emb(country_id) # (batch_size, emb_dim)\n",
    "        x = torch.cat([u_id, u_country], dim=-1) # (batch_size, emb_dim * 2)\n",
    "        out = self.mlp(x) # (batch_size, tower_dim)\n",
    "        # optional: L2-normalise\n",
    "        out = F.normalize(out, p=2, dim=-1)\n",
    "        return out\n",
    "\n",
    "class ItemTower(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.item_emb = nn.Embedding(n_items, emb_dim)\n",
    "        self.cat_emb = nn.Embedding(n_categories, emb_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 2, tower_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(tower_dim, tower_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, item_id, category_id):\n",
    "        \"\"\"\n",
    "        Perform forward pass of item tower for the batch of items. The items contains both\n",
    "        positive and negative samples.\n",
    "\n",
    "        Args:\n",
    "            item_id: Tensor of shape (batch_size, N)\n",
    "            category_id: Tensor of shape (batch_size, N)\n",
    "        \"\"\"\n",
    "        i_id = self.item_emb(item_id) # (batch_size, N, emb_dim)\n",
    "        i_cat = self.cat_emb(category_id) # (batch_size, N, emb_dim)\n",
    "        x = torch.cat([i_id, i_cat], dim=-1) # (batch_size, N, emb_dim * 2)\n",
    "        out = self.mlp(x) # (batch_size, tower_dim)\n",
    "        # optional: L2-normalise\n",
    "        out = F.normalize(out, p=2, dim=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user_tower = UserTower()\n",
    "        self.item_tower = ItemTower()\n",
    "    \n",
    "    def forward(self, user_id, country_id, item_id, category_id):\n",
    "        user_vec = self.user_tower(user_id, country_id) # (batch_size, tower_dim)\n",
    "        item_vec = self.item_tower(item_id, category_id) # (batch_size, N, tower_dim)\n",
    "        # Expand user_vec to match item_vec shape\n",
    "        user_exp_vec = user_vec.unsqueeze(1).expand(-1, item_vec.size(1), -1) # (batch_size, 1, tower_dim)\n",
    "        # Compute dot product similarity\n",
    "        logits = torch.sum(user_exp_vec * item_vec, dim=-1) # (batch_size,)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a73ba9",
   "metadata": {},
   "source": [
    "# Negative Sampling Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd8d979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative sampling dataset\n",
    "class TwoTowerNegSamplingDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 interactions: Sequence[Tuple], # Sequence of (user_id, pos_item_id)\n",
    "                 user_to_hard_negs: Dict[int, List[int]],\n",
    "                 all_item_ids: Sequence[int], # Catalog of all item IDs\n",
    "                 num_hard_negs: int = 2, # number of hard negatives per positive\n",
    "                 num_random_negs: int = 2, # number of random negatives per positive\n",
    "                 user_to_pos_items: Dict[int, List[int]] = None # optional mapping of user to their positive items\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Dataset for two-tower model with negative sampling (1 positive + hard negatives + random negatives).\n",
    "        Args:\n",
    "            interactions: List of (user_id, pos_item_id) tuples.\n",
    "            user_to_hard_negs: Dict mapping user_id to list of hard negative item_ids.\n",
    "            all_item_ids: Sequence of all item IDs in the catalog.\n",
    "            num_hard_negs: Number of hard negatives to sample per positive.\n",
    "            num_random_negs: Number of random negatives to sample per positive.\n",
    "            user_to_pos_items: Optional dict mapping user_id to their positive item_ids to avoid sampling positives as negatives.\n",
    "        \"\"\"\n",
    "        self.interactions = list(interactions)\n",
    "        self.user_to_hard_negs = user_to_hard_negs\n",
    "        self.all_item_ids = all_item_ids\n",
    "        self.num_hard_negs = num_hard_negs\n",
    "        self.num_random_negs = num_random_negs\n",
    "        self.user_to_pos_items = user_to_pos_items or self._build_user_pos_items()\n",
    "        # Convert all_item_ids to a set for faster lookup\n",
    "        self.all_item_id_set = set(all_item_ids)\n",
    "    \n",
    "    def _build_user_pos_items(self) -> Dict[int, List[int]]:\n",
    "        user_pos = {}\n",
    "        for u_id, i_id in self.interactions:\n",
    "            user_pos.setdefault(u_id, []).append(i_id)\n",
    "        return user_pos\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.interactions)\n",
    "\n",
    "    def _sample_hard_negs(self, user_id: int, pos_item_id: int) -> List[int]:\n",
    "        hard_negs = self.user_to_hard_negs.get(user_id, [])\n",
    "        # Remove the positive items from hard negatives\n",
    "        filtered = [i for i in hard_negs if i != pos_item_id]\n",
    "        if not filtered:\n",
    "            return []\n",
    "        if len(filtered) <= self.num_hard_negs:\n",
    "            # If not enough hard negatives, return all available\n",
    "            return filtered\n",
    "        else:\n",
    "            # otherwise, randomly sample the required number\n",
    "            sampled = random.sample(filtered, min(self.num_hard_negs, len(filtered)))\n",
    "            return sampled\n",
    "    \n",
    "    def _sample_random_negs(self, user_id: int, pos_item_id: int) -> List[int]:\n",
    "        \"\"\"\n",
    "        Sample random negatives ensuring they are not in user's positive items.\n",
    "        - Randomly sample from all_item_ids until we have enough valid negatives.\n",
    "        - If a sampled item is already a positive for the user, drop it and sample again.\n",
    "        \"\"\"\n",
    "        user_pos_items = set(self.user_to_pos_items.get(user_id, [])) # Filter in-batch negatives\n",
    "        negatives = []\n",
    "        attempts = 0\n",
    "        max_attempts = self.num_random_negs * 10  # to avoid infinite loop\n",
    "        while len(negatives) < self.num_random_negs and attempts < max_attempts:\n",
    "            sampled_item = random.choice(self.all_item_ids)\n",
    "            if sampled_item != pos_item_id and sampled_item not in user_pos_items:\n",
    "                negatives.append(sampled_item)\n",
    "            attempts += 1\n",
    "        return negatives\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        For each interaction, return:\n",
    "        - one positive interaction (user_id, pos_item_id)\n",
    "        - num_hard_negs hard negative item_ids\n",
    "        - num_random_negs random negative item_ids\n",
    "\n",
    "        Returns:\n",
    "            user_id: int\n",
    "            pos_item_id: int\n",
    "        \"\"\"\n",
    "        user_id, pos_item_id = self.interactions[idx]\n",
    "\n",
    "        # 1) Positive\n",
    "        item_ids = [pos_item_id]\n",
    "        labels = [1.0]\n",
    "\n",
    "        # 2) Hard negatives\n",
    "        hard_negs = self._sample_hard_negs(user_id, pos_item_id)\n",
    "        item_ids.extend(hard_negs)\n",
    "        labels.extend([0.0] * len(hard_negs))\n",
    "\n",
    "        # 3) Random negatives\n",
    "        random_negs = self._sample_random_negs(user_id, pos_item_id)\n",
    "        item_ids.extend(random_negs)\n",
    "        labels.extend([0.0] * len(random_negs))\n",
    "\n",
    "        # 4) convert to tensors\n",
    "        user_id_tensor = torch.tensor(user_id, dtype=torch.long)\n",
    "        item_ids_tensor = torch.tensor(item_ids, dtype=torch.long)\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        return {\n",
    "            'user_id': user_id_tensor, # Scalar tensor\n",
    "            'item_ids': item_ids_tensor, # Shape: (1 + num_hard_negs + num_random_negs,)\n",
    "            'labels': labels_tensor # Shape: (1 + num_hard_negs + num_random_negs,)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f555f74",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523c84e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 3. One training step\n",
    "# ---------------------------\n",
    "model = TwoTowerModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TwoTowerNegSamplingDataset(\n",
    "    interactions=[(0, 10), (1, 20), (2, 30)], # example interactions\n",
    "    user_to_hard_negs={\n",
    "        0: [11, 12, 13],\n",
    "        1: [21, 22, 23],\n",
    "        2: [31, 32, 33]\n",
    "    },\n",
    "    all_item_ids=list(range(n_items)),\n",
    "    num_hard_negs=2,\n",
    "    num_random_negs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d15f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=32, shuffle=True) # DataLoader for batching\n",
    "\n",
    "for batch in loader:\n",
    "    user_ids = batch['user_id']          # (B,)\n",
    "    item_ids = batch['item_ids']         # (B, N)\n",
    "    labels = batch['labels']             # (B, N)\n",
    "\n",
    "    logits = model(\n",
    "        user_ids,\n",
    "        torch.zeros_like(user_ids), # dummy country_id\n",
    "        item_ids,\n",
    "        torch.zeros_like(item_ids)  # dummy category_id\n",
    "    )  # (B, N)\n",
    "    loss = loss_fn(logits.view(-1), labels.view(-1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward() # calculate gradients\n",
    "    optimizer.step() # update parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08539a24",
   "metadata": {},
   "source": [
    "# Precompute Item Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # set model to eval mode\n",
    "user_tower = model.user_tower\n",
    "item_tower = model.item_tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbfa42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ids_all = torch.arange(n_items) # (n_items,)\n",
    "\n",
    "with torch.no_grad():\n",
    "    def compute_item_embeddings(item_ids, batch_size = 1024) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Precompute item embeddings for all items in the catalog.\n",
    "        Returns:\n",
    "            item_embeddings: Tensor of shape (n_items, batch_size, tower_dim)\n",
    "        \"\"\"\n",
    "        embs = []\n",
    "        for i in range(0, len(item_ids), batch_size):\n",
    "            batch = item_ids[i:i+batch_size]\n",
    "            # reshape to (batch_size, 1)\n",
    "            batch = batch.unsqueeze(1)\n",
    "            v = item_tower(batch)\n",
    "            v = v.squeeze(1) # (batch_size, tower_dim)\n",
    "            embs.append(v)\n",
    "        return torch.cat(embs, dim=0) # (n_items, tower_dim)\n",
    "    \n",
    "    item_embeddings = compute_item_embeddings(item_ids_all) # (n_items, tower_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b044b5d9",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "\n",
    "Two-tower at inference: retrieval with precomputed item embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8724cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss # FAISS library for efficient similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd58677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build FAISS index\n",
    "d = item_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(d) # inner product index\n",
    "index.add(item_embeddings.cpu().numpy()) # add item embeddings to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ba9b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend for a given user\n",
    "def recommend_for_user(user_id: int, country_id: int, top_k: int = 10) -> List[Tuple[int, float]]:\n",
    "    \"\"\"\n",
    "    Recommend top-k items for the given user using FAISS index.\n",
    "    Args:\n",
    "        user_id: int\n",
    "        country_id: int\n",
    "        top_k: int\n",
    "    Returns:\n",
    "        List of (item_id, score) tuples\n",
    "    \"\"\"\n",
    "    user_id_tensor = torch.tensor([user_id], dtype=torch.long)\n",
    "    country_id_tensor = torch.tensor([country_id], dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        user_vec = user_tower(user_id_tensor, country_id_tensor) # (1, tower_dim)\n",
    "        user_vec_np = user_vec.cpu().numpy().astype('float32') # FAISS requires float32\n",
    "        # Search in FAISS index\n",
    "        D, I = index.search(user_vec_np, top_k) # D: distances, I: indices\n",
    "        recommendations = [(int(item_id), float(score)) for item_id, score in zip(I[0], D[0])]\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae6d67",
   "metadata": {},
   "source": [
    "# Offline Evaluation\n",
    "\n",
    "Common evaluation metrics for recommendation problems are:\n",
    "\n",
    "__Hit@K__: did the true item appear in the top-K?\n",
    "\n",
    "__Recall@K__: what fraction of the user's \"relevant\" items are in the top-K? Recall@K is defined as\n",
    "\n",
    "```Recall@K = (# true positives in top-K) / (# total true positives)```\n",
    "\n",
    "Recall@K is the primary metric for two-tower retrieval.\n",
    "\n",
    "For example,\n",
    "```\n",
    "Ground truth = {7, 10, 25}\n",
    "Ranking = [3, 7, 10, 2, 25, 14, ...]\n",
    "```\n",
    "\n",
    "then \n",
    "* Hit@3 → True (because 7 and 10 are in the top 3)\n",
    "* Recall@3 → 2/3 (the model retrieved 2 of the 3 relevant items)\n",
    "\n",
    "NDCG@K (Normalised Discounted Cumulative Gain) is a more nuanced ranking metric. \n",
    "* Top positions get high weight\n",
    "* Lower positions get discounted\n",
    "* Supports multiple positives\n",
    "\n",
    "Usually, it is defined as:\n",
    "\n",
    "NDCG@K = DCG / IDCG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52453d64",
   "metadata": {},
   "source": [
    "__MRR (Mean Reciprocal Rank)__ rewards placing the true item very high. \n",
    "\n",
    "```if the true item is at rank 2 --> MRR = 1/2```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0aed83",
   "metadata": {},
   "source": [
    "Instead of evaluating using all items in the catalog (often contains millions of items), the industry pattern is to use positive + sampled negatives to build the evaluation set. Here is the steps:\n",
    "1.\tPick positives for evaluation\n",
    "Items the user interacted with at test time (not in training).\n",
    "2.\tSample negatives\n",
    "* Often ~100 random items\n",
    "* or ~1000 items from similar category\n",
    "* Optionally: the same negatives used in training are avoided\n",
    "3.\tScore them\n",
    "Use:\n",
    "* user_tower(user_id)\n",
    "* item_tower(candidate_items)\n",
    "* dot product similarity\n",
    "4.\tRank\n",
    "Sort by score descending.\n",
    "5.\tCompute metrics\n",
    "* Hit@K\n",
    "* Recall@K\n",
    "* MRR (mean reciprocal rank)\n",
    "* NDCG@K (discounts position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "689ee14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_users, user_to_test_pos, all_items, K=10, num_neg = 100):\n",
    "    model.eval() # set model to eval mode\n",
    "    user_tower = model.user_tower\n",
    "    item_tower = model.item_tower\n",
    "\n",
    "    hit_count = 0\n",
    "    recall_count = 0\n",
    "    total_positives = 0\n",
    "\n",
    "    for user in test_users:\n",
    "        pos_items = user_to_test_pos[user]\n",
    "        total_positives += len(pos_items)\n",
    "\n",
    "        # 1) Sample negatives\n",
    "        neg_items = torch.tensor(\n",
    "            random.sample(all_items, num_neg),\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        # 2) Form candidate set = positives + negatives\n",
    "        candidate_items = torch.cat([\n",
    "            torch.tensor(pos_items, dtype=torch.long),\n",
    "            neg_items\n",
    "        ]) # (num_pos + num_neg,)\n",
    "\n",
    "        # 3) Score them\n",
    "        user_tensor = torch.tensor([user], dtype=torch.long)\n",
    "        u = user_tower(user_tensor) # (1, tower_dim)\n",
    "        v = item_tower(candidate_items.unsqueeze(1)).squeeze(1)  # (num_candidates, tower_dim)\n",
    "        scores = torch.matmul(v, u.squeeze(0)) # (num_candidates,)\n",
    "\n",
    "        # 4) Rank\n",
    "        topk_indices = torch.topk(scores, K).indices # (K,)\n",
    "        topk_items = candidate_items[topk_indices] # (K,)\n",
    "\n",
    "        # 5) Metrices\n",
    "        # Hit@K\n",
    "        if any(item in pos_items for item in topk_items):\n",
    "            hit_count += 1\n",
    "        \n",
    "        # Recall@K\n",
    "        recall_count += sum(1 for item in topk_items if item in pos_items)\n",
    "\n",
    "        return {\n",
    "            'Hit@K': hit_count / len(test_users),\n",
    "            'Recall@K': recall_count / total_positives\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f59a580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "two_tower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
